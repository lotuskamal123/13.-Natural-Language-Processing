{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "443623ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52374b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 130: expected 4 fields, saw 8\\nSkipping line 343: expected 4 fields, saw 7\\nSkipping line 664: expected 4 fields, saw 5\\nSkipping line 666: expected 4 fields, saw 5\\nSkipping line 1010: expected 4 fields, saw 5\\nSkipping line 1337: expected 4 fields, saw 6\\nSkipping line 1338: expected 4 fields, saw 6\\nSkipping line 1346: expected 4 fields, saw 5\\nSkipping line 1355: expected 4 fields, saw 9\\n'\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv(\"WhatsApp Chat with Online Class Hope AI.txt\",header=None,error_bad_lines=False,encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4edc2bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23/07/2023</td>\n",
       "      <td>6:16‚ÄØam - Messages and calls are end-to-end e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23/07/2023</td>\n",
       "      <td>6:16‚ÄØam - Online Class Hope AI: *M.Manikandan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>üìÜ Customised Career Path Call has been Booked.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>üìù *Meeting Details*</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>*Scheduled Time:* 03:45pm - Wednesday</td>\n",
       "      <td>July 26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1270</th>\n",
       "      <td>29/04/2024</td>\n",
       "      <td>9:15‚ÄØam - Manika: &lt;Media omitted&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1271</th>\n",
       "      <td>29/04/2024</td>\n",
       "      <td>9:52‚ÄØam - Manika: &lt;Media omitted&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1272</th>\n",
       "      <td>29/04/2024</td>\n",
       "      <td>9:56‚ÄØam - Manika: &lt;Media omitted&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1273</th>\n",
       "      <td>07/05/2024</td>\n",
       "      <td>10:48‚ÄØpm - Manika: https://github.com/AI23man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1274</th>\n",
       "      <td>11/05/2024</td>\n",
       "      <td>11:43‚ÄØam - Manika: https://github.com/AI23man...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1275 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  \\\n",
       "0                                         23/07/2023   \n",
       "1                                         23/07/2023   \n",
       "2     üìÜ Customised Career Path Call has been Booked.   \n",
       "3                               üìù *Meeting Details*    \n",
       "4              *Scheduled Time:* 03:45pm - Wednesday   \n",
       "...                                              ...   \n",
       "1270                                      29/04/2024   \n",
       "1271                                      29/04/2024   \n",
       "1272                                      29/04/2024   \n",
       "1273                                      07/05/2024   \n",
       "1274                                      11/05/2024   \n",
       "\n",
       "                                                      1  \n",
       "0      6:16‚ÄØam - Messages and calls are end-to-end e...  \n",
       "1      6:16‚ÄØam - Online Class Hope AI: *M.Manikandan...  \n",
       "2                                                   NaN  \n",
       "3                                                   NaN  \n",
       "4                                               July 26  \n",
       "...                                                 ...  \n",
       "1270                  9:15‚ÄØam - Manika: <Media omitted>  \n",
       "1271                  9:52‚ÄØam - Manika: <Media omitted>  \n",
       "1272                  9:56‚ÄØam - Manika: <Media omitted>  \n",
       "1273   10:48‚ÄØpm - Manika: https://github.com/AI23man...  \n",
       "1274   11:43‚ÄØam - Manika: https://github.com/AI23man...  \n",
       "\n",
       "[1275 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(columns=[2, 3], inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eafc8ede",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Name</th>\n",
       "      <th>Chat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23/07/2023</td>\n",
       "      <td>6:16‚ÄØam</td>\n",
       "      <td>Messages and calls are end-to-end encrypted. ...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23/07/2023</td>\n",
       "      <td>6:16‚ÄØam</td>\n",
       "      <td>Online Class Hope AI</td>\n",
       "      <td>*M.Manikandan* *!! Successfully your slot has...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>üìÜ Customised Career Path Call has been Booked.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>üìù *Meeting Details*</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>*Scheduled Time:* 03:45pm - Wednesday</td>\n",
       "      <td>July 26</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1270</th>\n",
       "      <td>29/04/2024</td>\n",
       "      <td>9:15‚ÄØam</td>\n",
       "      <td>Manika</td>\n",
       "      <td>&lt;Media omitted&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1271</th>\n",
       "      <td>29/04/2024</td>\n",
       "      <td>9:52‚ÄØam</td>\n",
       "      <td>Manika</td>\n",
       "      <td>&lt;Media omitted&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1272</th>\n",
       "      <td>29/04/2024</td>\n",
       "      <td>9:56‚ÄØam</td>\n",
       "      <td>Manika</td>\n",
       "      <td>&lt;Media omitted&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1273</th>\n",
       "      <td>07/05/2024</td>\n",
       "      <td>10:48‚ÄØpm</td>\n",
       "      <td>Manika</td>\n",
       "      <td>https://github.com/AI23mani/Time_Series_All_A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1274</th>\n",
       "      <td>11/05/2024</td>\n",
       "      <td>11:43‚ÄØam</td>\n",
       "      <td>Manika</td>\n",
       "      <td>https://github.com/AI23mani/Time-Series-Analysis</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1275 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Date        Time  \\\n",
       "0                                         23/07/2023    6:16‚ÄØam    \n",
       "1                                         23/07/2023    6:16‚ÄØam    \n",
       "2     üìÜ Customised Career Path Call has been Booked.         NaN   \n",
       "3                               üìù *Meeting Details*          NaN   \n",
       "4              *Scheduled Time:* 03:45pm - Wednesday     July 26   \n",
       "...                                              ...         ...   \n",
       "1270                                      29/04/2024    9:15‚ÄØam    \n",
       "1271                                      29/04/2024    9:52‚ÄØam    \n",
       "1272                                      29/04/2024    9:56‚ÄØam    \n",
       "1273                                      07/05/2024   10:48‚ÄØpm    \n",
       "1274                                      11/05/2024   11:43‚ÄØam    \n",
       "\n",
       "                                                   Name  \\\n",
       "0      Messages and calls are end-to-end encrypted. ...   \n",
       "1                                  Online Class Hope AI   \n",
       "2                                                   NaN   \n",
       "3                                                   NaN   \n",
       "4                                                  None   \n",
       "...                                                 ...   \n",
       "1270                                             Manika   \n",
       "1271                                             Manika   \n",
       "1272                                             Manika   \n",
       "1273                                             Manika   \n",
       "1274                                             Manika   \n",
       "\n",
       "                                                   Chat  \n",
       "0                                                  None  \n",
       "1      *M.Manikandan* *!! Successfully your slot has...  \n",
       "2                                                   NaN  \n",
       "3                                                   NaN  \n",
       "4                                                  None  \n",
       "...                                                 ...  \n",
       "1270                                    <Media omitted>  \n",
       "1271                                    <Media omitted>  \n",
       "1272                                    <Media omitted>  \n",
       "1273   https://github.com/AI23mani/Time_Series_All_A...  \n",
       "1274   https://github.com/AI23mani/Time-Series-Analysis  \n",
       "\n",
       "[1275 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df.columns=['Date','Chat']\n",
    "Message=df[\"Chat\"].str.split(\"-\",n=1,expand=True)\n",
    "df[\"Time\"]=Message[0]\n",
    "Message1=Message[1].str.split(\":\",n=1,expand=True)\n",
    "df[\"Name\"]=Message1[0]\n",
    "df[\"Chat\"]=Message1[1]\n",
    "df=df[[\"Date\",\"Time\",\"Name\",\"Chat\"]]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "201c8e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1275 entries, 0 to 1274\n",
      "Data columns (total 4 columns):\n",
      "Date    1275 non-null object\n",
      "Time    1001 non-null object\n",
      "Name    950 non-null object\n",
      "Chat    943 non-null object\n",
      "dtypes: object(4)\n",
      "memory usage: 40.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc9e1fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfee94b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b09701e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37f9c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38df37d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c700d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "sid = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb316a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "senti=sid.polarity_scores(dataset['Chat'][1274])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186e9f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "senti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7846a0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    " def sentimentalAnalysis(data,columnname):\n",
    "        \n",
    "        #downloading vader_lexicon for the process\n",
    "        import matplotlib.pyplot as plt\n",
    "        import seaborn as sns\n",
    "        \"Importing Necessary Packeage\"\n",
    "        from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "        sid = SentimentIntensityAnalyzer()\n",
    "        \n",
    "        \"Deleting null pr empty value\"\n",
    "        data.dropna(inplace=True)\n",
    "        \n",
    "        \"Checking for a comment\"\n",
    "        #sid.polarity_scores(data[columnname][93])\n",
    "        \n",
    "        \"Creating respective columns\"\n",
    "        \n",
    "        data['scores'] = data[columnname].apply(lambda commentText: sid.polarity_scores(commentText))\n",
    "        data['compound']  = data['scores'].apply(lambda score_dict: score_dict['compound'])\n",
    "        data['Negtive']  = data['scores'].apply(lambda score_dict: score_dict['neg'])\n",
    "        data['Postive']  = data['scores'].apply(lambda score_dict: score_dict['pos'])\n",
    "        data['Neutral']  = data['scores'].apply(lambda score_dict: score_dict['neu'])\n",
    "        \n",
    "        \"Creating final pos or neg using compound score\"\n",
    "        data['comp_score'] = data['compound'].apply(lambda c: 'pos' if c >=0 else 'neg')\n",
    "        plt.clf()\n",
    "        #comp=sns.countplot(x = 'comp_score', hue = 'Name', data = data, palette = 'magma')\n",
    "        #comp.figure.savefig(\"date_charts.png\")\n",
    "        \"Checking how many pos and neg\"\n",
    "        posneg=pd.DataFrame(data['comp_score'].value_counts())\n",
    "        return posneg,data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27869df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos,data_Senti=sentimentalAnalysis(dataset,columnname='Chat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24377039",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_Senti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b485f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1977c2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "# Sample text data\n",
    "text_data = [\"Text document 1\", \"Text document 2\", \"Text document 3\"]\n",
    "\n",
    "# Step 1: Apply HashingVectorizer to convert text data into a matrix of token counts\n",
    "hash_vectorizer = HashingVectorizer(stop_words='english', n_features=1000)\n",
    "X = hash_vectorizer.fit_transform(text_data)\n",
    "\n",
    "# Step 2: Train the LDA model\n",
    "num_topics = 5\n",
    "lda_model = LatentDirichletAllocation(n_components=num_topics, random_state=42)\n",
    "lda_model.fit(X)\n",
    "\n",
    "# Step 3: Print the top words for each topic\n",
    "feature_names = hash_vectorizer.get_feature_names_out()\n",
    "for topic_idx, topic in enumerate(lda_model.components_):\n",
    "    top_words_indices = topic.argsort()[:-11:-1]\n",
    "    top_words = [feature_names[i] for i in top_words_indices]\n",
    "    print(f\"Topic {topic_idx + 1}: {top_words}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47114b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_results=lda_model.transform(dtm)\n",
    "df[\"Topic\"]=topic_results.argmax(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48b2175",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3990bcf8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[\"Topic\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b086c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install wordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573e3709",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=df\n",
    "from wordcloud import WordCloud\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5735c083",
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_words = []\n",
    "stoplist = stopwords.words('english')\n",
    "stoplist.extend(['omitted', 'voice','missed','call','video','deleted','media','message'])\n",
    "wordcloudss=\"This function saves image\"\n",
    "dataset.index=range(dataset.shape[0])\n",
    "for i in range(1,len(dataset)): \n",
    "    comment_words.append(dataset['Chat'][i])\n",
    "    vv=\" \".join(comment_words)          \n",
    "    wordcloud = WordCloud(width = 800, height = 800, \n",
    "                                background_color ='white', \n",
    "                                      stopwords = stoplist, \n",
    "                                      min_font_size = 10).generate(vv)         \n",
    "plt.figure(figsize = (9, 7), facecolor = None)\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\") \n",
    "plt.tight_layout(pad = 0) \n",
    "plt.savefig('wordcloud.PNG')\n",
    "plt.show() \n",
    "print(\"Successfully created\")\n",
    "wordcloudss=\"This function saves image\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b96cd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d7fc7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8572b4a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3ba870",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49bd481e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c88eeb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
