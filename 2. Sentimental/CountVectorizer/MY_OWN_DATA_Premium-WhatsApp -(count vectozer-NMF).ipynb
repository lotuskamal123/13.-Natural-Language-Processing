{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "443623ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52374b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"WhatsApp Chat with Online Class Hope AI.txt\",header=None,on_bad_lines='skip',encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4edc2bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23/07/2023</td>\n",
       "      <td>6:16 am - Messages and calls are end-to-end e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23/07/2023</td>\n",
       "      <td>6:16 am - Online Class Hope AI: *M.Manikandan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>📆 Customised Career Path Call has been Booked.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>📝 *Meeting Details*</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>*Scheduled Time:* 03:45pm - Wednesday</td>\n",
       "      <td>July 26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1270</th>\n",
       "      <td>29/04/2024</td>\n",
       "      <td>9:15 am - Manika: &lt;Media omitted&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1271</th>\n",
       "      <td>29/04/2024</td>\n",
       "      <td>9:52 am - Manika: &lt;Media omitted&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1272</th>\n",
       "      <td>29/04/2024</td>\n",
       "      <td>9:56 am - Manika: &lt;Media omitted&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1273</th>\n",
       "      <td>07/05/2024</td>\n",
       "      <td>10:48 pm - Manika: https://github.com/AI23man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1274</th>\n",
       "      <td>11/05/2024</td>\n",
       "      <td>11:43 am - Manika: https://github.com/AI23man...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1275 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  \\\n",
       "0                                         23/07/2023   \n",
       "1                                         23/07/2023   \n",
       "2     📆 Customised Career Path Call has been Booked.   \n",
       "3                               📝 *Meeting Details*    \n",
       "4              *Scheduled Time:* 03:45pm - Wednesday   \n",
       "...                                              ...   \n",
       "1270                                      29/04/2024   \n",
       "1271                                      29/04/2024   \n",
       "1272                                      29/04/2024   \n",
       "1273                                      07/05/2024   \n",
       "1274                                      11/05/2024   \n",
       "\n",
       "                                                      1  \n",
       "0      6:16 am - Messages and calls are end-to-end e...  \n",
       "1      6:16 am - Online Class Hope AI: *M.Manikandan...  \n",
       "2                                                   NaN  \n",
       "3                                                   NaN  \n",
       "4                                               July 26  \n",
       "...                                                 ...  \n",
       "1270                  9:15 am - Manika: <Media omitted>  \n",
       "1271                  9:52 am - Manika: <Media omitted>  \n",
       "1272                  9:56 am - Manika: <Media omitted>  \n",
       "1273   10:48 pm - Manika: https://github.com/AI23man...  \n",
       "1274   11:43 am - Manika: https://github.com/AI23man...  \n",
       "\n",
       "[1275 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(columns=[2, 3], inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eafc8ede",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Name</th>\n",
       "      <th>Chat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23/07/2023</td>\n",
       "      <td>6:16 am</td>\n",
       "      <td>Messages and calls are end-to-end encrypted. ...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23/07/2023</td>\n",
       "      <td>6:16 am</td>\n",
       "      <td>Online Class Hope AI</td>\n",
       "      <td>*M.Manikandan* *!! Successfully your slot has...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>📆 Customised Career Path Call has been Booked.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>📝 *Meeting Details*</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>*Scheduled Time:* 03:45pm - Wednesday</td>\n",
       "      <td>July 26</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1270</th>\n",
       "      <td>29/04/2024</td>\n",
       "      <td>9:15 am</td>\n",
       "      <td>Manika</td>\n",
       "      <td>&lt;Media omitted&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1271</th>\n",
       "      <td>29/04/2024</td>\n",
       "      <td>9:52 am</td>\n",
       "      <td>Manika</td>\n",
       "      <td>&lt;Media omitted&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1272</th>\n",
       "      <td>29/04/2024</td>\n",
       "      <td>9:56 am</td>\n",
       "      <td>Manika</td>\n",
       "      <td>&lt;Media omitted&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1273</th>\n",
       "      <td>07/05/2024</td>\n",
       "      <td>10:48 pm</td>\n",
       "      <td>Manika</td>\n",
       "      <td>https://github.com/AI23mani/Time_Series_All_A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1274</th>\n",
       "      <td>11/05/2024</td>\n",
       "      <td>11:43 am</td>\n",
       "      <td>Manika</td>\n",
       "      <td>https://github.com/AI23mani/Time-Series-Analysis</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1275 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Date        Time  \\\n",
       "0                                         23/07/2023    6:16 am    \n",
       "1                                         23/07/2023    6:16 am    \n",
       "2     📆 Customised Career Path Call has been Booked.         NaN   \n",
       "3                               📝 *Meeting Details*          NaN   \n",
       "4              *Scheduled Time:* 03:45pm - Wednesday     July 26   \n",
       "...                                              ...         ...   \n",
       "1270                                      29/04/2024    9:15 am    \n",
       "1271                                      29/04/2024    9:52 am    \n",
       "1272                                      29/04/2024    9:56 am    \n",
       "1273                                      07/05/2024   10:48 pm    \n",
       "1274                                      11/05/2024   11:43 am    \n",
       "\n",
       "                                                   Name  \\\n",
       "0      Messages and calls are end-to-end encrypted. ...   \n",
       "1                                  Online Class Hope AI   \n",
       "2                                                   NaN   \n",
       "3                                                   NaN   \n",
       "4                                                  None   \n",
       "...                                                 ...   \n",
       "1270                                             Manika   \n",
       "1271                                             Manika   \n",
       "1272                                             Manika   \n",
       "1273                                             Manika   \n",
       "1274                                             Manika   \n",
       "\n",
       "                                                   Chat  \n",
       "0                                                  None  \n",
       "1      *M.Manikandan* *!! Successfully your slot has...  \n",
       "2                                                   NaN  \n",
       "3                                                   NaN  \n",
       "4                                                  None  \n",
       "...                                                 ...  \n",
       "1270                                    <Media omitted>  \n",
       "1271                                    <Media omitted>  \n",
       "1272                                    <Media omitted>  \n",
       "1273   https://github.com/AI23mani/Time_Series_All_A...  \n",
       "1274   https://github.com/AI23mani/Time-Series-Analysis  \n",
       "\n",
       "[1275 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df.columns=['Date','Chat']\n",
    "Message=df[\"Chat\"].str.split(\"-\",n=1,expand=True)\n",
    "df[\"Time\"]=Message[0]\n",
    "Message1=Message[1].str.split(\":\",n=1,expand=True)\n",
    "df[\"Name\"]=Message1[0]\n",
    "df[\"Chat\"]=Message1[1]\n",
    "df=df[[\"Date\",\"Time\",\"Name\",\"Chat\"]]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "201c8e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1275 entries, 0 to 1274\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Date    1275 non-null   object\n",
      " 1   Time    1001 non-null   object\n",
      " 2   Name    950 non-null    object\n",
      " 3   Chat    943 non-null    object\n",
      "dtypes: object(4)\n",
      "memory usage: 40.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc9e1fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cfee94b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\ADMIN\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b09701e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c37f9c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_3356\\2639109627.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset.dropna(inplace=True)\n"
     ]
    }
   ],
   "source": [
    "dataset.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c700d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "sid = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eeb316a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "senti=sid.polarity_scores(dataset['Chat'][1274])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "186e9f76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "senti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7846a0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    " def sentimentalAnalysis(data,columnname):\n",
    "        \n",
    "        #downloading vader_lexicon for the process\n",
    "        import matplotlib.pyplot as plt\n",
    "        import seaborn as sns\n",
    "        \"Importing Necessary Packeage\"\n",
    "        from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "        sid = SentimentIntensityAnalyzer()\n",
    "        \n",
    "        \"Deleting null pr empty value\"\n",
    "        data.dropna(inplace=True)\n",
    "        \n",
    "        \"Checking for a comment\"\n",
    "        #sid.polarity_scores(data[columnname][93])\n",
    "        \n",
    "        \"Creating respective columns\"\n",
    "        \n",
    "        data['scores'] = data[columnname].apply(lambda commentText: sid.polarity_scores(commentText))\n",
    "        data['compound']  = data['scores'].apply(lambda score_dict: score_dict['compound'])\n",
    "        data['Negtive']  = data['scores'].apply(lambda score_dict: score_dict['neg'])\n",
    "        data['Postive']  = data['scores'].apply(lambda score_dict: score_dict['pos'])\n",
    "        data['Neutral']  = data['scores'].apply(lambda score_dict: score_dict['neu'])\n",
    "        \n",
    "        \"Creating final pos or neg using compound score\"\n",
    "        data['comp_score'] = data['compound'].apply(lambda c: 'pos' if c >=0 else 'neg')\n",
    "        plt.clf()\n",
    "        #comp=sns.countplot(x = 'comp_score', hue = 'Name', data = data, palette = 'magma')\n",
    "        #comp.figure.savefig(\"date_charts.png\")\n",
    "        \"Checking how many pos and neg\"\n",
    "        posneg=pd.DataFrame(data['comp_score'].value_counts())\n",
    "        return posneg,data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "27869df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_3356\\2009568695.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data.dropna(inplace=True)\n",
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_3356\\2009568695.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['scores'] = data[columnname].apply(lambda commentText: sid.polarity_scores(commentText))\n",
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_3356\\2009568695.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['compound']  = data['scores'].apply(lambda score_dict: score_dict['compound'])\n",
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_3356\\2009568695.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['Negtive']  = data['scores'].apply(lambda score_dict: score_dict['neg'])\n",
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_3356\\2009568695.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['Postive']  = data['scores'].apply(lambda score_dict: score_dict['pos'])\n",
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_3356\\2009568695.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['Neutral']  = data['scores'].apply(lambda score_dict: score_dict['neu'])\n",
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_3356\\2009568695.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['comp_score'] = data['compound'].apply(lambda c: 'pos' if c >=0 else 'neg')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pos,data_Senti=sentimentalAnalysis(dataset,columnname='Chat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "24377039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Name</th>\n",
       "      <th>Chat</th>\n",
       "      <th>scores</th>\n",
       "      <th>compound</th>\n",
       "      <th>Negtive</th>\n",
       "      <th>Postive</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>comp_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23/07/2023</td>\n",
       "      <td>6:16 am</td>\n",
       "      <td>Online Class Hope AI</td>\n",
       "      <td>*M.Manikandan* *!! Successfully your slot has...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.632, 'pos': 0.368, 'comp...</td>\n",
       "      <td>0.6219</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.368</td>\n",
       "      <td>0.632</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>25/07/2023</td>\n",
       "      <td>8:54 pm</td>\n",
       "      <td>Manika</td>\n",
       "      <td>Please update my mail id</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.635, 'pos': 0.365, 'comp...</td>\n",
       "      <td>0.3182</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.635</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>25/07/2023</td>\n",
       "      <td>8:54 pm</td>\n",
       "      <td>Manika</td>\n",
       "      <td>maridevamani90@gmail.com</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>25/07/2023</td>\n",
       "      <td>8:55 pm</td>\n",
       "      <td>Manika</td>\n",
       "      <td>Tomorrow my schedule time</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>25/07/2023</td>\n",
       "      <td>8:55 pm</td>\n",
       "      <td>Manika</td>\n",
       "      <td>Link still not come</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1270</th>\n",
       "      <td>29/04/2024</td>\n",
       "      <td>9:15 am</td>\n",
       "      <td>Manika</td>\n",
       "      <td>&lt;Media omitted&gt;</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1271</th>\n",
       "      <td>29/04/2024</td>\n",
       "      <td>9:52 am</td>\n",
       "      <td>Manika</td>\n",
       "      <td>&lt;Media omitted&gt;</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1272</th>\n",
       "      <td>29/04/2024</td>\n",
       "      <td>9:56 am</td>\n",
       "      <td>Manika</td>\n",
       "      <td>&lt;Media omitted&gt;</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1273</th>\n",
       "      <td>07/05/2024</td>\n",
       "      <td>10:48 pm</td>\n",
       "      <td>Manika</td>\n",
       "      <td>https://github.com/AI23mani/Time_Series_All_A...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1274</th>\n",
       "      <td>11/05/2024</td>\n",
       "      <td>11:43 am</td>\n",
       "      <td>Manika</td>\n",
       "      <td>https://github.com/AI23mani/Time-Series-Analysis</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>943 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date        Time                   Name  \\\n",
       "1     23/07/2023    6:16 am    Online Class Hope AI   \n",
       "12    25/07/2023    8:54 pm                  Manika   \n",
       "13    25/07/2023    8:54 pm                  Manika   \n",
       "14    25/07/2023    8:55 pm                  Manika   \n",
       "15    25/07/2023    8:55 pm                  Manika   \n",
       "...          ...         ...                    ...   \n",
       "1270  29/04/2024    9:15 am                  Manika   \n",
       "1271  29/04/2024    9:52 am                  Manika   \n",
       "1272  29/04/2024    9:56 am                  Manika   \n",
       "1273  07/05/2024   10:48 pm                  Manika   \n",
       "1274  11/05/2024   11:43 am                  Manika   \n",
       "\n",
       "                                                   Chat  \\\n",
       "1      *M.Manikandan* *!! Successfully your slot has...   \n",
       "12                             Please update my mail id   \n",
       "13                             maridevamani90@gmail.com   \n",
       "14                            Tomorrow my schedule time   \n",
       "15                                  Link still not come   \n",
       "...                                                 ...   \n",
       "1270                                    <Media omitted>   \n",
       "1271                                    <Media omitted>   \n",
       "1272                                    <Media omitted>   \n",
       "1273   https://github.com/AI23mani/Time_Series_All_A...   \n",
       "1274   https://github.com/AI23mani/Time-Series-Analysis   \n",
       "\n",
       "                                                 scores  compound  Negtive  \\\n",
       "1     {'neg': 0.0, 'neu': 0.632, 'pos': 0.368, 'comp...    0.6219      0.0   \n",
       "12    {'neg': 0.0, 'neu': 0.635, 'pos': 0.365, 'comp...    0.3182      0.0   \n",
       "13    {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...    0.0000      0.0   \n",
       "14    {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...    0.0000      0.0   \n",
       "15    {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...    0.0000      0.0   \n",
       "...                                                 ...       ...      ...   \n",
       "1270  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...    0.0000      0.0   \n",
       "1271  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...    0.0000      0.0   \n",
       "1272  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...    0.0000      0.0   \n",
       "1273  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...    0.0000      0.0   \n",
       "1274  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...    0.0000      0.0   \n",
       "\n",
       "      Postive  Neutral comp_score  \n",
       "1       0.368    0.632        pos  \n",
       "12      0.365    0.635        pos  \n",
       "13      0.000    1.000        pos  \n",
       "14      0.000    1.000        pos  \n",
       "15      0.000    1.000        pos  \n",
       "...       ...      ...        ...  \n",
       "1270    0.000    1.000        pos  \n",
       "1271    0.000    1.000        pos  \n",
       "1272    0.000    1.000        pos  \n",
       "1273    0.000    1.000        pos  \n",
       "1274    0.000    1.000        pos  \n",
       "\n",
       "[943 rows x 10 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_Senti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2b485f8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comp_score</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pos</th>\n",
       "      <td>931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neg</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            count\n",
       "comp_score       \n",
       "pos           931\n",
       "neg            12"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c192fd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Count Vectorization\n",
    "count_vectorizer = CountVectorizer(max_df=1.0, min_df=1, stop_words='english')  # Adjust min_df and max_df values\n",
    "dtm = count_vectorizer.fit_transform(df['Chat'])\n",
    "\n",
    "# NMF Model\n",
    "num_topics = 5\n",
    "nmf_model = NMF(n_components=num_topics, random_state=42)\n",
    "nmf_model.fit(dtm)\n",
    "\n",
    "# Display the top words for each topic\n",
    "for index, topic in enumerate(nmf_model.components_):\n",
    "    top_words_indices = topic.argsort()[-10:]\n",
    "    top_words = [count_vectorizer.get_feature_names()[i] for i in top_words_indices]\n",
    "    print(f\"Topic {index + 1}: {top_words}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d47114b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_3356\\1889149295.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Topic\"]=topic_results.argmax(axis=1)\n"
     ]
    }
   ],
   "source": [
    "topic_results=nmf_model.transform(dtm)\n",
    "df[\"Topic\"]=topic_results.argmax(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b48b2175",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Name</th>\n",
       "      <th>Chat</th>\n",
       "      <th>scores</th>\n",
       "      <th>compound</th>\n",
       "      <th>Negtive</th>\n",
       "      <th>Postive</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>comp_score</th>\n",
       "      <th>Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23/07/2023</td>\n",
       "      <td>6:16 am</td>\n",
       "      <td>Online Class Hope AI</td>\n",
       "      <td>*M.Manikandan* *!! Successfully your slot has...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.632, 'pos': 0.368, 'comp...</td>\n",
       "      <td>0.6219</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.368</td>\n",
       "      <td>0.632</td>\n",
       "      <td>pos</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>25/07/2023</td>\n",
       "      <td>8:54 pm</td>\n",
       "      <td>Manika</td>\n",
       "      <td>Please update my mail id</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.635, 'pos': 0.365, 'comp...</td>\n",
       "      <td>0.3182</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.635</td>\n",
       "      <td>pos</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>25/07/2023</td>\n",
       "      <td>8:54 pm</td>\n",
       "      <td>Manika</td>\n",
       "      <td>maridevamani90@gmail.com</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>pos</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>25/07/2023</td>\n",
       "      <td>8:55 pm</td>\n",
       "      <td>Manika</td>\n",
       "      <td>Tomorrow my schedule time</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>pos</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>25/07/2023</td>\n",
       "      <td>8:55 pm</td>\n",
       "      <td>Manika</td>\n",
       "      <td>Link still not come</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>pos</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1270</th>\n",
       "      <td>29/04/2024</td>\n",
       "      <td>9:15 am</td>\n",
       "      <td>Manika</td>\n",
       "      <td>&lt;Media omitted&gt;</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>pos</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1271</th>\n",
       "      <td>29/04/2024</td>\n",
       "      <td>9:52 am</td>\n",
       "      <td>Manika</td>\n",
       "      <td>&lt;Media omitted&gt;</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>pos</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1272</th>\n",
       "      <td>29/04/2024</td>\n",
       "      <td>9:56 am</td>\n",
       "      <td>Manika</td>\n",
       "      <td>&lt;Media omitted&gt;</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>pos</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1273</th>\n",
       "      <td>07/05/2024</td>\n",
       "      <td>10:48 pm</td>\n",
       "      <td>Manika</td>\n",
       "      <td>https://github.com/AI23mani/Time_Series_All_A...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>pos</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1274</th>\n",
       "      <td>11/05/2024</td>\n",
       "      <td>11:43 am</td>\n",
       "      <td>Manika</td>\n",
       "      <td>https://github.com/AI23mani/Time-Series-Analysis</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>pos</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>943 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date        Time                   Name  \\\n",
       "1     23/07/2023    6:16 am    Online Class Hope AI   \n",
       "12    25/07/2023    8:54 pm                  Manika   \n",
       "13    25/07/2023    8:54 pm                  Manika   \n",
       "14    25/07/2023    8:55 pm                  Manika   \n",
       "15    25/07/2023    8:55 pm                  Manika   \n",
       "...          ...         ...                    ...   \n",
       "1270  29/04/2024    9:15 am                  Manika   \n",
       "1271  29/04/2024    9:52 am                  Manika   \n",
       "1272  29/04/2024    9:56 am                  Manika   \n",
       "1273  07/05/2024   10:48 pm                  Manika   \n",
       "1274  11/05/2024   11:43 am                  Manika   \n",
       "\n",
       "                                                   Chat  \\\n",
       "1      *M.Manikandan* *!! Successfully your slot has...   \n",
       "12                             Please update my mail id   \n",
       "13                             maridevamani90@gmail.com   \n",
       "14                            Tomorrow my schedule time   \n",
       "15                                  Link still not come   \n",
       "...                                                 ...   \n",
       "1270                                    <Media omitted>   \n",
       "1271                                    <Media omitted>   \n",
       "1272                                    <Media omitted>   \n",
       "1273   https://github.com/AI23mani/Time_Series_All_A...   \n",
       "1274   https://github.com/AI23mani/Time-Series-Analysis   \n",
       "\n",
       "                                                 scores  compound  Negtive  \\\n",
       "1     {'neg': 0.0, 'neu': 0.632, 'pos': 0.368, 'comp...    0.6219      0.0   \n",
       "12    {'neg': 0.0, 'neu': 0.635, 'pos': 0.365, 'comp...    0.3182      0.0   \n",
       "13    {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...    0.0000      0.0   \n",
       "14    {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...    0.0000      0.0   \n",
       "15    {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...    0.0000      0.0   \n",
       "...                                                 ...       ...      ...   \n",
       "1270  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...    0.0000      0.0   \n",
       "1271  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...    0.0000      0.0   \n",
       "1272  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...    0.0000      0.0   \n",
       "1273  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...    0.0000      0.0   \n",
       "1274  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...    0.0000      0.0   \n",
       "\n",
       "      Postive  Neutral comp_score  Topic  \n",
       "1       0.368    0.632        pos      4  \n",
       "12      0.365    0.635        pos      4  \n",
       "13      0.000    1.000        pos      1  \n",
       "14      0.000    1.000        pos      1  \n",
       "15      0.000    1.000        pos      4  \n",
       "...       ...      ...        ...    ...  \n",
       "1270    0.000    1.000        pos      0  \n",
       "1271    0.000    1.000        pos      0  \n",
       "1272    0.000    1.000        pos      0  \n",
       "1273    0.000    1.000        pos      1  \n",
       "1274    0.000    1.000        pos      1  \n",
       "\n",
       "[943 rows x 11 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3990bcf8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Topic\n",
       "0    501\n",
       "4    212\n",
       "2    107\n",
       "1     78\n",
       "3     45\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Topic\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1b086c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wordCloud\n",
      "  Obtaining dependency information for wordCloud from https://files.pythonhosted.org/packages/f5/b0/247159f61c5d5d6647171bef84430b7efad4db504f0229674024f3a4f7f2/wordcloud-1.9.3-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading wordcloud-1.9.3-cp311-cp311-win_amd64.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: numpy>=1.6.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from wordCloud) (1.26.4)\n",
      "Requirement already satisfied: pillow in c:\\users\\admin\\anaconda3\\lib\\site-packages (from wordCloud) (9.4.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\admin\\anaconda3\\lib\\site-packages (from wordCloud) (3.8.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from matplotlib->wordCloud) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from matplotlib->wordCloud) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from matplotlib->wordCloud) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from matplotlib->wordCloud) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from matplotlib->wordCloud) (23.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from matplotlib->wordCloud) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from matplotlib->wordCloud) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->wordCloud) (1.16.0)\n",
      "Downloading wordcloud-1.9.3-cp311-cp311-win_amd64.whl (300 kB)\n",
      "   ---------------------------------------- 0.0/300.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/300.2 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/300.2 kB ? eta -:--:--\n",
      "   --- ----------------------------------- 30.7/300.2 kB 262.6 kB/s eta 0:00:02\n",
      "   ----- --------------------------------- 41.0/300.2 kB 245.8 kB/s eta 0:00:02\n",
      "   ----------- --------------------------- 92.2/300.2 kB 476.3 kB/s eta 0:00:01\n",
      "   ------------------ ------------------- 143.4/300.2 kB 566.5 kB/s eta 0:00:01\n",
      "   ------------------------ ------------- 194.6/300.2 kB 653.6 kB/s eta 0:00:01\n",
      "   ------------------------ ------------- 194.6/300.2 kB 653.6 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 286.7/300.2 kB 768.0 kB/s eta 0:00:01\n",
      "   -------------------------------------- 300.2/300.2 kB 712.3 kB/s eta 0:00:00\n",
      "Installing collected packages: wordCloud\n",
      "Successfully installed wordCloud-1.9.3\n"
     ]
    }
   ],
   "source": [
    "# !pip install wordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "573e3709",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ADMIN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset=df\n",
    "from wordcloud import WordCloud\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28290fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_words = []\n",
    "stoplist = stopwords.words('english')\n",
    "stoplist.extend(['omitted', 'voice','missed','call','video','deleted','media','message'])\n",
    "wordcloudss=\"This function saves image\"\n",
    "dataset.index=range(dataset.shape[0])\n",
    "for i in range(1,len(dataset)): \n",
    "    comment_words.append(dataset['Chat'][i])\n",
    "    vv=\" \".join(comment_words)          \n",
    "    wordcloud = WordCloud(width = 800, height = 800, \n",
    "                                background_color ='white', \n",
    "                                      stopwords = stoplist, \n",
    "                                      min_font_size = 10).generate(vv)         \n",
    "plt.figure(figsize = (9, 7), facecolor = None)\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\") \n",
    "plt.tight_layout(pad = 0) \n",
    "plt.savefig('wordcloud.PNG')\n",
    "plt.show() \n",
    "print(\"Successfully created\")\n",
    "wordcloudss=\"This function saves image\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b96cd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49bd481e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c88eeb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
